{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "IMl_266sSy0K",
        "outputId": "3e3fa034-41b7-4c9d-b0f4-c6e94b1d60f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "\u001b[33mWARNING: Skipping scikit-surprise as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting scikit-surprise\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Collecting numpy>=1.19.5 (from scikit-surprise)\n",
            "  Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.15.2)\n",
            "Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp311-cp311-linux_x86_64.whl size=2505206 sha256=ae14e2c581fed5f642b5a47b5d0a3106a9fbd78a86e0f8cd8196fe67dc87e2e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/8f/6e/7e2899163e2d85d8266daab4aa1cdabec7a6c56f83c015b5af\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: numpy, scikit-surprise\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.5 scikit-surprise-1.1.4\n",
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.5\n",
            "    Uninstalling numpy-2.2.5:\n",
            "      Successfully uninstalled numpy-2.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 2.1.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.3.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.22.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.3.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "3e940f3d6a544b40a026226d3e22038b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#this step is needed to run in google colab to prevent dependency issues\n",
        "!pip uninstall numpy scikit-surprise -y\n",
        "!pip install scikit-surprise\n",
        "!pip install numpy==1.23.5\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
        "from surprise import Dataset, Reader, SVDpp\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import GridSearchCV\n"
      ],
      "metadata": {
        "id": "J5tFQ6ZsTGqU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import files**\n",
        "\n",
        "Import files and run some of the data preprocessing steps written by Shreyas"
      ],
      "metadata": {
        "id": "u60kkUWzB0yL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessed files generated by code from shreyas\n",
        "#train = pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "#test = pd.read_csv('/content/drive/MyDrive/test.csv')\n",
        "#val = pd.read_csv('/content/drive/MyDrive/val.csv')\n",
        "train=pd.read_csv('../Two tower model/Restaurant_Recommendation/data/train.csv')\n",
        "test=pd.read_csv('../Two tower model/Restaurant_Recommendation/data/test.csv')\n",
        "val=pd.read_csv('../Two tower model/Restaurant_Recommendation/data/val.csv')"
      ],
      "metadata": {
        "id": "j5CYss92TJdO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#code from shreyas, use the same user and restaurant features\n",
        "def create_dataset(data):\n",
        "    # User features\n",
        "    user_features = {\n",
        "        'review_count': data['review_count_norm_x'].values.astype(np.float32),\n",
        "        'average_stars': data['average_stars_norm'].values.astype(np.float32),\n",
        "        'fans': data['fans_norm'].values.astype(np.float32),\n",
        "        'friends_count': data['friends_count_norm'].values.astype(np.float32),\n",
        "        'elite': data['elite_binary'].values.astype(np.float32)\n",
        "    }\n",
        "    #added this section to convert parking column values to 1,0 due to error\n",
        "    parking_columns = ['park_garage', 'park_street', 'park_validated', 'park_lot', 'park_valet']\n",
        "    for col in parking_columns:\n",
        "        data[col] = data[col].map({'True': 1.0, 'False': 0.0, True: 1.0, False: 0.0}).fillna(0.0)\n",
        "\n",
        "    # Restaurant features\n",
        "    rest_features = {\n",
        "        'stars': data['stars_norm'].values.astype(np.float32),\n",
        "        'review_count': data['review_count_norm_y'].values.astype(np.float32),\n",
        "        'lat': data['lat_norm'].values.astype(np.float32),\n",
        "        'lon': data['lon_norm'].values.astype(np.float32),\n",
        "        'categories': data[[f'cat_{i}' for i in range(50)]].values.astype(np.float32),\n",
        "        'parking': data[['park_garage', 'park_street', 'park_validated', 'park_lot', 'park_valet']].values.astype(np.float32)\n",
        "    }\n",
        "\n",
        "    # Labels (target variable)\n",
        "    labels = data['stars'].values.astype(np.float32)\n",
        "\n",
        "    return user_features, rest_features, labels"
      ],
      "metadata": {
        "id": "FotOq271TLv4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#code from shreyas - research.ipynb\n",
        "train_user, train_rest, train_labels = create_dataset(train)\n",
        "val_user, val_rest, val_labels = create_dataset(val)\n",
        "test_user, test_rest, test_labels = create_dataset(test)"
      ],
      "metadata": {
        "id": "IipC8XGTTN63"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 1: XGBoost**\n",
        "\n",
        "XGBoost with a content based approach"
      ],
      "metadata": {
        "id": "sBm6FkFQCB7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#combine features to create a model that uses restaurant features\n",
        "def combine_features(user_features, rest_features):\n",
        "    # Convert dictionaries to arrays\n",
        "    user_array = np.column_stack([user_features[k] for k in user_features.keys()])\n",
        "    rest_array = np.column_stack([rest_features[k] for k in rest_features.keys() if k != 'categories'])\n",
        "\n",
        "    # Flatten categories\n",
        "    categories_array = rest_features['categories']\n",
        "\n",
        "    # Combine all features\n",
        "    combined_features = np.column_stack([user_array, rest_array, categories_array])\n",
        "    return combined_features\n",
        "\n",
        "X_train = combine_features(train_user, train_rest)\n",
        "X_val = combine_features(val_user, val_rest)\n",
        "X_test = combine_features(test_user, test_rest)\n",
        "\n",
        "y_train = train_labels\n",
        "y_val = val_labels\n",
        "y_test = test_labels"
      ],
      "metadata": {
        "id": "pH065-6aTQXp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import xgboost as xgb\n",
        "\n",
        "# create an xgb model\n",
        "xgb_model = xgb.XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    eval_metric='rmse',\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# kept best parameters\n",
        "param_grid = {\n",
        "    'max_depth': [5],\n",
        "    'learning_rate': [0.1],\n",
        "    'n_estimators': [100],\n",
        "    'subsample': [0.8],\n",
        "    'colsample_bytree': [1.0],\n",
        "    'gamma': [0.1]\n",
        "}\n",
        "\n",
        "#use gridsearch\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_grid=param_grid,\n",
        "    scoring='neg_root_mean_squared_error',\n",
        "    cv=5,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# run grid_search for the besst model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# save best model\n",
        "best_model = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "VBD5GTHGTVBH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c53c099-3836-419e-b0d4-6d2ce65c8902"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# evalute on validation set and test set\n",
        "xgb_val_preds = best_model.predict(X_val)\n",
        "xgb_test_preds = best_model.predict(X_test)\n",
        "\n",
        "#calculate rmse\n",
        "xgb_val_mse = mean_squared_error(y_val, xgb_val_preds)\n",
        "xgb_test_mse = mean_squared_error(y_test, xgb_test_preds)\n",
        "xgb_val_rmse = np.sqrt(xgb_val_mse)\n",
        "xgb_test_rmse = np.sqrt(xgb_test_mse)\n",
        "\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Validation RMSE: {xgb_val_rmse:.4f}\")\n",
        "#calculate mae\n",
        "xgb_test_mae = mean_absolute_error(y_test, xgb_test_preds)\n",
        "print(f\"Test MAE: {xgb_test_mae:.4f}\")"
      ],
      "metadata": {
        "id": "AeVpGsl0Csce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43f8d5ca-0065-40b5-c15b-b9d5ebbb4dd7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'colsample_bytree': 1.0, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.8}\n",
            "Validation RMSE: 1.0687\n",
            "Test MAE: 0.8048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 2: SVD++**\n",
        "\n",
        "SVD++ for collaborative filtering"
      ],
      "metadata": {
        "id": "4Nli5K_0CN04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise.model_selection import GridSearchCV\n",
        "\n",
        "# Prepare the data\n",
        "train_cf = train[['user_id', 'business_id', 'stars']]\n",
        "val_cf = val[['user_id', 'business_id', 'stars']]\n",
        "test_cf = test[['user_id', 'business_id', 'stars']]\n",
        "\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "train_data = Dataset.load_from_df(train_cf, reader)\n",
        "\n",
        "# some of the better params\n",
        "param_grid = {\n",
        "    'n_factors': [10, 0],\n",
        "    'n_epochs': [20],\n",
        "    'lr_all': [0.01],\n",
        "    'reg_all': [0.3],\n",
        "    'random_state': [42]\n",
        "}\n",
        "\n",
        "# Set up GridSearchCV using SVDpp\n",
        "gs = GridSearchCV(\n",
        "    SVDpp,\n",
        "    param_grid,\n",
        "    measures=['rmse', 'mae'],\n",
        "    cv=5,\n",
        "    refit='rmse',\n",
        "    n_jobs=1,\n",
        "    joblib_verbose=2\n",
        ")\n",
        "\n",
        "# Fit the grid search\n",
        "gs.fit(train_data)\n",
        "\n",
        "# Print the results\n",
        "print(\"Best RMSE:\", gs.best_score['rmse'])\n",
        "print(\"Best MAE:\", gs.best_score['mae'])\n",
        "print(\"Best params:\", gs.best_params['rmse'])\n"
      ],
      "metadata": {
        "id": "IMR88MuhTYep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b0739b7-6fd8-4d88-92cc-956971682204"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RMSE: 1.3438052457114833\n",
            "Best MAE: 1.0994207248434331\n",
            "Best params: {'n_factors': 0, 'n_epochs': 20, 'lr_all': 0.01, 'reg_all': 0.3, 'random_state': 42}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_svd(svd_model, df):\n",
        "    testset = list(df.itertuples(index=False, name=None))\n",
        "    predictions = svd_model.test(testset)\n",
        "    return np.array([pred.est for pred in predictions])"
      ],
      "metadata": {
        "id": "2izY5HO_TbCq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svdpp = gs.best_estimator['rmse']\n",
        "\n",
        "# Predict using SVD\n",
        "svdpp_val_preds = predict_svd(svdpp, val_cf)\n",
        "svdpp_test_preds = predict_svd(svdpp, test_cf)\n",
        "\n",
        "# Actual ratings\n",
        "val_true = val_cf['stars'].values\n",
        "test_true = test_cf['stars'].values\n",
        "\n",
        "# Compute RMSE\n",
        "val_rmse = np.sqrt(mean_squared_error(val_true, svdpp_val_preds))\n",
        "test_rmse = np.sqrt(mean_squared_error(test_true, svdpp_test_preds))\n",
        "\n",
        "print(f\"Validation RMSE: {val_rmse:.4f}\")\n",
        "print(f\"Test RMSE: {test_rmse:.4f}\")\n",
        "test_mae = mean_absolute_error(test_true, svdpp_test_preds)\n",
        "print(f\"Test MAE: {test_mae:.4f}\")"
      ],
      "metadata": {
        "id": "J3NHneCD3EvD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad40dd83-f76a-4ce3-fcfb-7870a53fd83e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation RMSE: 1.3332\n",
            "Test RMSE: 1.3331\n",
            "Test MAE: 1.0888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1st Hybrid Approach: Random Forest**"
      ],
      "metadata": {
        "id": "KBc4cngOv7bO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_meta_features(svdpp_preds, xgb_preds):\n",
        "    return pd.DataFrame({\n",
        "        'svdpp_pred': svdpp_preds,\n",
        "        'xgb_pred': xgb_preds\n",
        "    })\n",
        "\n",
        "def prepare_meta_data(svdpp_model, xgb_model, X, df_cf):\n",
        "    svdpp_preds = predict_svd(svdpp_model, df_cf)\n",
        "    xgb_preds = xgb_model.predict(X)\n",
        "    meta_X = create_meta_features(svdpp_preds, xgb_preds)\n",
        "    meta_y = df_cf['stars'].values\n",
        "    return meta_X, meta_y\n",
        "\n",
        "\n",
        "# Prepare meta-features for train, test, val\n",
        "X_meta_train, y_meta_train = prepare_meta_data(svdpp, best_model, X_train, train_cf)\n",
        "X_meta_val, y_meta_val = prepare_meta_data(svdpp, best_model, X_val, val_cf)\n",
        "X_meta_test, y_meta_test = prepare_meta_data(svdpp, best_model, X_test, test_cf)"
      ],
      "metadata": {
        "id": "584W_YaVYhog"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#Kept best hyperparameters\n",
        "param_grid = {\n",
        "    'n_estimators': [150],\n",
        "    'max_depth': [10],\n",
        "    'min_samples_split': [30],\n",
        "    'min_samples_leaf': [4],\n",
        "    'random_state': [42]\n",
        "}\n",
        "\n",
        "#call randomforest model\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "# set up gridsearch\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf,\n",
        "    param_grid=param_grid,\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    scoring='neg_mean_squared_error')\n",
        "\n",
        "#fit model\n",
        "grid_search.fit(X_meta_train, y_meta_train)\n",
        "\n",
        "#save best model\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict on the test set using the tuned Random Forest model\n",
        "rf_preds_val = best_rf_model.predict(X_meta_val)\n",
        "rf_preds_test = best_rf_model.predict(X_meta_test)\n",
        "rf_rmse_val = np.sqrt(mean_squared_error(y_meta_val, rf_preds_val))\n",
        "rf_rmse_test = np.sqrt(mean_squared_error(y_meta_test, rf_preds_test))\n",
        "\n",
        "# Print out the best hyperparameters and RMSE\n",
        "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
        "print(f\"Test RMSE (Random Forest): {rf_rmse_test:.4f}\")\n",
        "print(f\"Val RMSE (Random Forest): {rf_rmse_val:.4f}\")\n",
        "#mae\n",
        "rf_mae_test = mean_absolute_error(y_meta_test, rf_preds_test)\n",
        "print(f\"Test MAE (Random Forest): {rf_mae_test:.4f}\")"
      ],
      "metadata": {
        "id": "W52GgYXCYrzb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eedd21b-ddc1-445e-c5fc-17476997f157"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Best Hyperparameters: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 30, 'n_estimators': 150, 'random_state': 42}\n",
            "Test RMSE (Random Forest): 1.3334\n",
            "Val RMSE (Random Forest): 1.3343\n",
            "Test MAE (Random Forest): 0.9803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2nd Hybird Approach: Ensemble**"
      ],
      "metadata": {
        "id": "QEHS0Uryvt5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_alpha = None\n",
        "best_rmse = float(\"inf\")\n",
        "\n",
        "for alpha in np.arange(0.9, 1.10, 0.005):\n",
        "    val_blend = alpha * xgb_val_preds + (1 - alpha) * np.array(svdpp_val_preds)\n",
        "    rmse = np.sqrt(mean_squared_error(y_meta_val, val_blend))\n",
        "\n",
        "    if rmse < best_rmse:\n",
        "        best_rmse = rmse\n",
        "        best_alpha = alpha\n",
        "\n",
        "print(f\"Best alpha: {best_alpha:.3f}\")\n",
        "print(f\"Best RMSE: {best_rmse:.4f}\")"
      ],
      "metadata": {
        "id": "3JYy79ni6m-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dd65a3f-6442-4984-9b8a-b43943a05641"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best alpha: 0.995\n",
            "Best RMSE: 1.0687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val = val_cf['stars'].values\n",
        "y_test = test_cf['stars'].values\n",
        "\n",
        "# Blend SVD and XGBoost predictions using best alpha\n",
        "val_ensemble_preds = best_alpha * xgb_val_preds + (1 - best_alpha) * svdpp_val_preds\n",
        "test_ensemble_preds = best_alpha * xgb_test_preds + (1 - best_alpha) * svdpp_test_preds\n",
        "\n",
        "# Compute RMSE\n",
        "val_rmse = np.sqrt(mean_squared_error(y_val, val_ensemble_preds))\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, test_ensemble_preds))\n",
        "test_mae = mean_absolute_error(y_test, test_ensemble_preds)\n",
        "\n",
        "print(f\"Validation RMSE (Ensemble): {val_rmse:.4f}\")\n",
        "print(f\"Test RMSE (Ensemble): {test_rmse:.4f}\")\n",
        "print(f\"Test MAE (Ensemble): {test_mae:.4f}\")"
      ],
      "metadata": {
        "id": "crg7IzWa6rla",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "549234db-8d37-4e3c-bc11-54a4c71f8c2e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation RMSE (Ensemble): 1.0687\n",
            "Test RMSE (Ensemble): 1.0699\n",
            "Test MAE (Ensemble): 0.8054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3rd Hybrid Approach: Residuals**\n",
        "\n",
        "Utilize XGB predictions and train residuals on SVD++"
      ],
      "metadata": {
        "id": "WT-clC9ikSYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Utilize XGBoost predictions and train residuals using SVD++\n",
        "#val and test already explicitly called\n",
        "xgb_train_preds = best_model.predict(X_train)\n",
        "\n",
        "#compute residuals\n",
        "residuals_train = y_train - xgb_train_preds\n",
        "\n",
        "#build Surprise dataset with residuals\n",
        "train_resid_df = train_cf.copy()\n",
        "train_resid_df['stars'] = residuals_train\n",
        "\n",
        "data = Dataset.load_from_df(train_resid_df[['user_id', 'business_id', 'stars']], reader)\n",
        "trainset_resid = data.build_full_trainset()\n",
        "\n",
        "#train SVD++ on residuals\n",
        "svdpp_resid = SVDpp()\n",
        "svdpp_resid.fit(trainset_resid)\n",
        "\n",
        "#predict residuals on val\n",
        "val_resid_testset = list(val_cf.itertuples(index=False, name=None))\n",
        "svdpp_resid_preds = svdpp_resid.test(val_resid_testset)\n",
        "svdpp_resid_vals = np.array([pred.est for pred in svdpp_resid_preds])\n",
        "\n",
        "#predict residuals on test\n",
        "test_resid_testset = list(test_cf.itertuples(index=False, name=None))\n",
        "svdpp_resid_test_preds = svdpp_resid.test(test_resid_testset)\n",
        "svdpp_resid_test_vals = np.array([pred.est for pred in svdpp_resid_test_preds])\n",
        "\n",
        "#calculate rmse for validation\n",
        "residual_val_blend = xgb_val_preds + svdpp_resid_vals\n",
        "val_rmse = np.sqrt(mean_squared_error(y_val, residual_val_blend))\n",
        "print(f\"Validation RMSE (Residual Hybrid): {val_rmse:.4f}\")\n",
        "\n",
        "#calculate rmse for test\n",
        "residual_test_blend = xgb_test_preds + svdpp_resid_test_vals\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, residual_test_blend))\n",
        "test_mae = mean_absolute_error(y_test, residual_test_blend)\n",
        "print(f\"Test RMSE (Residual Hybrid): {test_rmse:.4f}\")\n",
        "print(f\"Test MAE: {test_mae:.4f}\")"
      ],
      "metadata": {
        "id": "SIJiARgBkXBY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d25d71a-3af0-42fa-dadf-d25d620171c6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation RMSE (Residual Hybrid): 1.4622\n",
            "Test RMSE (Residual Hybrid): 1.4638\n",
            "Test MAE: 1.1401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.5 Residuals Reversed**\n",
        "\n",
        "Utilize SVD++ predictions and train residuals on XGB"
      ],
      "metadata": {
        "id": "qRJiV1OKmNER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Opposite, use SVD++ and train residuals on XGBoost\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "#Use SVD++ predictions and calculate residual\n",
        "svdpp_train_preds = predict_svd(svdpp, train_cf)\n",
        "residuals_train = y_train - svdpp_train_preds\n",
        "\n",
        "#initialize XGBoost\n",
        "xgb_resid = XGBRegressor(random_state=42)\n",
        "\n",
        "# hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100],\n",
        "    'max_depth': [0,5],\n",
        "    'learning_rate': [0.05],\n",
        "    'subsample': [0.8],\n",
        "    'colsample_bytree': [0.9]\n",
        "}\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=xgb_resid, param_grid=param_grid, cv=2, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')\n",
        "\n",
        "# fit dataset\n",
        "grid_search.fit(X_train, residuals_train)\n",
        "\n",
        "# Get the best model from the grid search\n",
        "best_xgb_resid = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "uTTbmM171V_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15158365-54d0-4b7b-b625-ebb74d91105f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict SVD++ on val/test\n",
        "val_testset = list(val_cf.itertuples(index=False, name=None))\n",
        "test_testset = list(test_cf.itertuples(index=False, name=None))\n",
        "\n",
        "svdpp_val_preds = svdpp.test(val_testset)\n",
        "svdpp_test_preds = svdpp.test(test_testset)\n",
        "\n",
        "# check extracted values\n",
        "svdpp_val_vals = np.array([pred.est for pred in svdpp_val_preds])\n",
        "svdpp_test_vals = np.array([pred.est for pred in svdpp_test_preds])\n",
        "\n",
        "# Predict residuals using XGBoost\n",
        "xgb_val_resid_preds = best_xgb_resid.predict(X_val)\n",
        "xgb_test_resid_preds = best_xgb_resid.predict(X_test)\n",
        "\n",
        "# final step, predict with SVD++ and XGBoosted residuals\n",
        "final_val_preds = svdpp_val_vals + xgb_val_resid_preds\n",
        "final_test_preds = svdpp_test_vals + xgb_test_resid_preds\n",
        "\n",
        "# RMSE to evaluate\n",
        "val_rmse = np.sqrt(mean_squared_error(y_val, final_val_preds))\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, final_test_preds))\n",
        "\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "print(f\"Validation RMSE (SVD++ + XGB residuals): {val_rmse:.4f}\")\n",
        "print(f\"Test RMSE (SVD++ + XGB residuals): {test_rmse:.4f}\")\n",
        "test_mae = mean_absolute_error(y_test, final_test_preds)\n",
        "print(f\"Test MAE: {test_mae:.4f}\")"
      ],
      "metadata": {
        "id": "m811IdXMKCK1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "392d23df-171b-4ae0-cc3d-9044201b4507"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'colsample_bytree': 0.9, 'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.8}\n",
            "Validation RMSE (SVD++ + XGB residuals): 1.1233\n",
            "Test RMSE (SVD++ + XGB residuals): 1.1239\n",
            "Test MAE: 0.8858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVD Model**\n",
        "\n",
        "Utilized SVD++ instead. Base model to showcase another baseline/result"
      ],
      "metadata": {
        "id": "_9alxl4iI8db"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import SVD\n",
        "from surprise.model_selection import GridSearchCV\n",
        "\n",
        "train_cf = train[['user_id', 'business_id', 'stars']]\n",
        "val_cf = val[['user_id', 'business_id', 'stars']]\n",
        "test_cf = test[['user_id', 'business_id', 'stars']]\n",
        "\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "train_data = Dataset.load_from_df(train_cf, reader)\n",
        "trainset = train_data.build_full_trainset()\n",
        "\n",
        "param_grid = {\n",
        "    'n_factors': [10, 0],\n",
        "    'n_epochs': [10],\n",
        "    'lr_all': [0.01],\n",
        "    'reg_all': [0.3],\n",
        "    'random_state': [42]\n",
        "}\n",
        "\n",
        "gs = GridSearchCV(\n",
        "    SVD,\n",
        "    param_grid,\n",
        "    measures=['rmse', 'mae'],\n",
        "    cv=3,\n",
        "    refit='rmse',\n",
        "    n_jobs=1,\n",
        "    joblib_verbose=2\n",
        ")\n",
        "\n",
        "# Fit gridsearch\n",
        "gs.fit(train_data)\n",
        "\n",
        "# Results\n",
        "print(\"Best RMSE:\", gs.best_score['rmse'])\n",
        "print(\"Best MAE:\", gs.best_score['mae'])\n",
        "print(\"Best params:\", gs.best_params['rmse'])\n",
        "\n",
        "# Get best model from grid search\n",
        "svd = gs.best_estimator['rmse']\n",
        "\n",
        "# Prepare validation testset\n",
        "val_testset = list(val_cf.itertuples(index=False, name=None))\n",
        "test_testset = list(test_cf.itertuples(index=False, name=None))\n",
        "\n",
        "\n",
        "# Make predictions on validation set\n",
        "val_predictions = svd.test(val_testset)\n",
        "test_predictions = svd.test(test_testset)\n",
        "\n",
        "# Compute RMSE\n",
        "val_rmse = accuracy.rmse(val_predictions)\n",
        "test_rmse = accuracy.rmse(test_predictions)\n",
        "print(f\"Validation RMSE: {val_rmse}\")\n",
        "print(f\"Test RMSE: {test_rmse}\")\n",
        "test_mae = accuracy.mae(test_predictions)\n",
        "print(f\"Test MAE: {test_mae}\")"
      ],
      "metadata": {
        "id": "MiM1iUACcaHD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d3869fb-25ec-4b21-d288-3c5ab009731c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RMSE: 1.3525376642668718\n",
            "Best MAE: 1.1103477024857618\n",
            "Best params: {'n_factors': 0, 'n_epochs': 10, 'lr_all': 0.01, 'reg_all': 0.3, 'random_state': 42}\n",
            "RMSE: 1.3379\n",
            "RMSE: 1.3379\n",
            "Validation RMSE: 1.3379098727140595\n",
            "Test RMSE: 1.337857236160567\n",
            "MAE:  1.0960\n",
            "Test MAE: 1.0960446732848521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hybrid Model**\n",
        "\n",
        "Utilize one basic hybrid model"
      ],
      "metadata": {
        "id": "nk1K8safI2p2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_meta_train, y_meta_train = prepare_meta_data(svd, best_model, X_train, train_cf)\n",
        "X_meta_val, y_meta_val = prepare_meta_data(svd, best_model, X_val, val_cf)\n",
        "X_meta_test, y_meta_test = prepare_meta_data(svd, best_model, X_test, test_cf)"
      ],
      "metadata": {
        "id": "7rI6RWsO_foe"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_alpha = None\n",
        "best_rmse = float(\"inf\")\n",
        "\n",
        "val_predictions = np.array([pred.est for pred in svd.test(val_testset)])\n",
        "test_predictions = np.array([test.est for test in svd.test(test_testset)])\n",
        "\n",
        "for alpha in np.arange(0.9, 1.10, 0.005):\n",
        "    val_blend = alpha * xgb_val_preds + (1 - alpha) * np.array(val_predictions)\n",
        "    rmse = np.sqrt(mean_squared_error(y_meta_val, val_blend))\n",
        "\n",
        "    if rmse < best_rmse:\n",
        "        best_rmse = rmse\n",
        "        best_alpha = alpha\n",
        "\n",
        "print(f\"Best alpha: {best_alpha:.3f}\")\n",
        "print(f\"Best RMSE: {best_rmse:.4f}\")"
      ],
      "metadata": {
        "id": "y0fHtJIxAAsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91aa01fe-c69f-4c15-9b65-361c8bfca5bc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best alpha: 0.995\n",
            "Best RMSE: 1.0687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val = val_cf['stars'].values\n",
        "y_test = test_cf['stars'].values\n",
        "\n",
        "# Blend SVD and XGBoost predictions using best alpha\n",
        "val_ensemble_preds = best_alpha * xgb_val_preds + (1 - best_alpha) * val_predictions\n",
        "test_ensemble_preds = best_alpha * xgb_test_preds + (1 - best_alpha) * test_predictions\n",
        "\n",
        "# Compute RMSE\n",
        "val_rmse = np.sqrt(mean_squared_error(y_val, val_ensemble_preds))\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, test_ensemble_preds))\n",
        "\n",
        "print(f\"Validation RMSE (Ensemble): {val_rmse:.4f}\")\n",
        "print(f\"Test RMSE (Ensemble): {test_rmse:.4f}\")"
      ],
      "metadata": {
        "id": "tLX5KC82AFs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a606c42-750f-48aa-d422-5b4d33aa9e7b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation RMSE (Ensemble): 1.0687\n",
            "Test RMSE (Ensemble): 1.0699\n"
          ]
        }
      ]
    }
  ]
}